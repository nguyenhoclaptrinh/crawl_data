import concurrent.futures
import json
import requests
from requests.exceptions import RequestException
from bs4 import BeautifulSoup
import urllib3
import time
import os
from crawl_url_pdf import download_pdf
from config import (BASE_URL, BASE_DOMAIN, DATASET_DIR, CHECKPOINT_DIR,
                    DEFAULT_MAX_PAGES, DEFAULT_BATCH_SIZE, MIN_BATCH_SIZE, MAX_BATCH_SIZE,
                    DROP_LEVELS_OPTIONS, DEFAULT_DROP_LEVELS, SEARCH_KEYWORD)
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)


def get_hidden_fields(response):
    try:
        soup = BeautifulSoup(response, "html.parser")

        hidden = {}

        for input_tag in soup.find_all("input", type="hidden"):
            if input_tag.get("name") and input_tag.get("value"):
                hidden[input_tag["name"]] = input_tag["value"]

        return hidden
    except RequestException as e:
        print(f"Error fetching hidden fields: {e}")
        return {}


def initialize_session():
    """Khá»Ÿi táº¡o session vÃ  láº¥y hidden fields ban Ä‘áº§u"""
    session = requests.Session()
    response = session.get(BASE_URL, verify=False)
    response.raise_for_status()
    hidden_fields = get_hidden_fields(response.text)
    return session, hidden_fields


def get_user_configuration():
    """Cho phÃ©p user nháº­p maxpages vÃ  tá»± Ä‘á»™ng tÃ­nh toÃ¡n batch configuration"""
    print("\n" + "="*60)
    print("âš™ï¸  Cáº¤U HÃŒNH CRAWL DATA")
    print("="*60)

    # Nháº­p sá»‘ pages tá»‘i Ä‘a
    while True:
        try:
            max_pages_input = input(
                f"ğŸ“„ Nháº­p sá»‘ pages tá»‘i Ä‘a Ä‘á»ƒ crawl (máº·c Ä‘á»‹nh {DEFAULT_MAX_PAGES}): ").strip()
            if not max_pages_input:
                max_pages = DEFAULT_MAX_PAGES
            else:
                max_pages = int(max_pages_input)
                if max_pages <= 0:
                    print("âŒ Sá»‘ pages pháº£i lá»›n hÆ¡n 0")
                    continue
            break
        except ValueError:
            print("âŒ Vui lÃ²ng nháº­p sá»‘ nguyÃªn há»£p lá»‡")

    # Tá»± Ä‘á»™ng tÃ­nh toÃ¡n batch size tá»‘i Æ°u hoáº·c cho user chá»n
    print(f"\nğŸ“Š Vá»›i {max_pages} pages, cÃ¡c tÃ¹y chá»n batch size:")

    # TÃ­nh toÃ¡n cÃ¡c tÃ¹y chá»n batch size há»£p lÃ½
    batch_options = calculate_batch_options(max_pages)

    for i, option in enumerate(batch_options):
        batch_size = option["batch_size"]
        num_batches = option["num_batches"]
        efficiency = option["efficiency"]
        print(
            f"  [{i+1}] Batch size {batch_size}: {num_batches} batches (hiá»‡u quáº£: {efficiency:.1f}%)")

    print(f"  [0] Tá»± nháº­p batch size")

    # User chá»n batch size
    while True:
        try:
            choice = input(
                f"\nChá»n tÃ¹y chá»n (1-{len(batch_options)} hoáº·c 0): ").strip()
            if not choice:
                # Máº·c Ä‘á»‹nh chá»n tÃ¹y chá»n Ä‘áº§u tiÃªn (tá»‘i Æ°u nháº¥t)
                chosen_batch_size = batch_options[0]["batch_size"]
                break

            choice_num = int(choice)
            if choice_num == 0:
                chosen_batch_size = get_custom_batch_size(max_pages)
                break
            elif 1 <= choice_num <= len(batch_options):
                chosen_batch_size = batch_options[choice_num - 1]["batch_size"]
                break
            else:
                print(f"âŒ Vui lÃ²ng chá»n tá»« 0 Ä‘áº¿n {len(batch_options)}")
        except ValueError:
            print("âŒ Vui lÃ²ng nháº­p sá»‘ nguyÃªn há»£p lá»‡")

    # TÃ­nh toÃ¡n sá»‘ batches
    num_batches = calculate_num_batches(max_pages, chosen_batch_size)

    print(f"\nâœ… Cáº¥u hÃ¬nh Ä‘Ã£ chá»n:")
    print(f"   ğŸ“„ Max pages: {max_pages}")
    print(f"   ğŸ“¦ Batch size: {chosen_batch_size}")
    print(f"   ğŸ”¢ Sá»‘ batches: {num_batches}")
    print(
        f"   ğŸ“Š Pages trong batch cuá»‘i: {max_pages % chosen_batch_size if max_pages % chosen_batch_size != 0 else chosen_batch_size}")

    return max_pages, chosen_batch_size, num_batches


def calculate_batch_options(max_pages):
    """TÃ­nh toÃ¡n cÃ¡c tÃ¹y chá»n batch size há»£p lÃ½"""
    options = []

    # Thá»­ cÃ¡c batch size tá»« MIN Ä‘áº¿n MAX
    for batch_size in range(MIN_BATCH_SIZE, min(MAX_BATCH_SIZE, max_pages) + 1):
        num_batches = calculate_num_batches(max_pages, batch_size)

        # TÃ­nh hiá»‡u quáº£ (% pages Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘áº§y Ä‘á»§)
        full_batches = max_pages // batch_size
        remaining_pages = max_pages % batch_size
        if remaining_pages == 0:
            efficiency = 100.0
        else:
            efficiency = (full_batches * batch_size +
                          remaining_pages) / (num_batches * batch_size) * 100

        options.append({
            "batch_size": batch_size,
            "num_batches": num_batches,
            "efficiency": efficiency
        })

    # Sáº¯p xáº¿p theo hiá»‡u quáº£ giáº£m dáº§n, rá»“i theo batch size tÄƒng dáº§n
    options.sort(key=lambda x: (-x["efficiency"], x["batch_size"]))

    # Chá»‰ tráº£ vá» 5 tÃ¹y chá»n tá»‘t nháº¥t
    return options[:5]


def get_custom_batch_size(max_pages):
    """Cho phÃ©p user nháº­p batch size tÃ¹y chá»‰nh"""
    while True:
        try:
            batch_size = int(input(
                f"ğŸ“¦ Nháº­p batch size ({MIN_BATCH_SIZE}-{min(MAX_BATCH_SIZE, max_pages)}): "))
            if MIN_BATCH_SIZE <= batch_size <= min(MAX_BATCH_SIZE, max_pages):
                return batch_size
            else:
                print(
                    f"âŒ Batch size pháº£i tá»« {MIN_BATCH_SIZE} Ä‘áº¿n {min(MAX_BATCH_SIZE, max_pages)}")
        except ValueError:
            print("âŒ Vui lÃ²ng nháº­p sá»‘ nguyÃªn há»£p lá»‡")


def calculate_num_batches(max_pages, batch_size):
    """TÃ­nh sá»‘ batches cáº§n thiáº¿t"""
    return (max_pages + batch_size - 1) // batch_size  # Ceiling division


def get_batch_page_range(batch_num, batch_size, max_pages):
    """TÃ­nh toÃ¡n start_page vÃ  end_page cho má»™t batch cá»¥ thá»ƒ"""
    start_page = (batch_num - 1) * batch_size + 1
    end_page = min(batch_num * batch_size, max_pages)
    return start_page, end_page


def get_checkpoint_filename(drop_levels, batch_num):
    """Táº¡o tÃªn file checkpoint theo DROP_LEVELS vÃ  batch number"""
    # Xá»­ lÃ½ trÆ°á»ng há»£p DROP_LEVELS rá»—ng
    level_code = drop_levels if drop_levels else "ALL"
    return f"checkpoint_{level_code}_{batch_num}.json"


def get_checkpoint_filepath(drop_levels, batch_num):
    """Láº¥y Ä‘Æ°á»ng dáº«n Ä‘áº§y Ä‘á»§ cá»§a file checkpoint"""
    if not os.path.exists(CHECKPOINT_DIR):
        os.makedirs(CHECKPOINT_DIR)

    filename = get_checkpoint_filename(drop_levels, batch_num)
    return os.path.join(CHECKPOINT_DIR, filename)


def create_checkpoint_structure(drop_levels, batch_num, start_page, end_page, max_pages, batch_size):
    """Táº¡o cáº¥u trÃºc checkpoint má»›i vá»›i thÃ´ng tin batch configuration"""
    return {
        "drop_levels": drop_levels,
        "drop_levels_name": DROP_LEVELS_OPTIONS.get(drop_levels, f"Cáº¥p {drop_levels}"),
        "batch_number": batch_num,
        "batch_size": batch_size,
        "max_pages": max_pages,
        "start_page": start_page,
        "end_page": end_page,
        "last_processed_page": 0,  # Page cuá»‘i cÃ¹ng Ä‘Ã£ xá»­ lÃ½ thÃ nh cÃ´ng
        "total_links_found": 0,
        "total_pdfs_downloaded": 0,
        "failed_pages": [],
        "completed_pages": [],
        "created_at": time.time(),
        "last_updated": time.time(),
        "is_completed": False
    }


def load_checkpoint(drop_levels, batch_num):
    """Táº£i checkpoint tá»« file cá»¥ thá»ƒ"""
    filepath = get_checkpoint_filepath(drop_levels, batch_num)

    if os.path.exists(filepath):
        with open(filepath, "r", encoding="utf-8") as f:
            checkpoint_data = json.load(f)
            print(
                f"âœ… Loaded checkpoint: {get_checkpoint_filename(drop_levels, batch_num)}")
            print(
                f"   ğŸ“„ Pages: {checkpoint_data['start_page']}-{checkpoint_data['end_page']}")
            print(
                f"   âœï¸  Last processed: {checkpoint_data['last_processed_page']}")
            print(f"   ğŸ”— Links found: {checkpoint_data['total_links_found']}")
            print(
                f"   ğŸ“¥ PDFs downloaded: {checkpoint_data['total_pdfs_downloaded']}")
            return checkpoint_data
    else:
        print(
            f"âŒ KhÃ´ng tÃ¬m tháº¥y checkpoint: {get_checkpoint_filename(drop_levels, batch_num)}")
        return None


def save_checkpoint(checkpoint_data):
    """LÆ°u checkpoint vÃ o file"""
    checkpoint_data["last_updated"] = time.time()

    filepath = get_checkpoint_filepath(
        checkpoint_data["drop_levels"],
        checkpoint_data["batch_number"]
    )

    with open(filepath, "w", encoding="utf-8") as f:
        json.dump(checkpoint_data, f, indent=2, ensure_ascii=False)

    filename = get_checkpoint_filename(
        checkpoint_data["drop_levels"],
        checkpoint_data["batch_number"]
    )
    print(f"ğŸ’¾ Saved checkpoint: {filename}")


def update_checkpoint_progress(checkpoint_data, page_num, links_found, success=True):
    """Cáº­p nháº­t tiáº¿n Ä‘á»™ xá»­ lÃ½ page"""
    if success:
        if page_num not in checkpoint_data["completed_pages"]:
            checkpoint_data["completed_pages"].append(page_num)
            checkpoint_data["total_links_found"] += links_found

        # Cáº­p nháº­t last_processed_page
        if page_num > checkpoint_data["last_processed_page"]:
            checkpoint_data["last_processed_page"] = page_num

        # XÃ³a khá»i failed_pages náº¿u cÃ³
        if page_num in checkpoint_data["failed_pages"]:
            checkpoint_data["failed_pages"].remove(page_num)
    else:
        if page_num not in checkpoint_data["failed_pages"]:
            checkpoint_data["failed_pages"].append(page_num)

    # Kiá»ƒm tra xem batch Ä‘Ã£ hoÃ n thÃ nh chÆ°a
    if checkpoint_data["last_processed_page"] >= checkpoint_data["end_page"]:
        checkpoint_data["is_completed"] = True

    return checkpoint_data


def list_all_checkpoints():
    """Liá»‡t kÃª táº¥t cáº£ checkpoint files cÃ³ sáºµn"""
    if not os.path.exists(CHECKPOINT_DIR):
        return []

    checkpoint_files = []
    for filename in os.listdir(CHECKPOINT_DIR):
        if filename.startswith("checkpoint_") and filename.endswith(".json"):
            # Parse filename: checkpoint_{drop_levels}_{batch}.json
            parts = filename.replace("checkpoint_", "").replace(
                ".json", "").split("_")
            if len(parts) >= 2:
                drop_levels = parts[0] if parts[0] != "ALL" else ""
                try:
                    batch_num = int(parts[1])
                    checkpoint_files.append({
                        "filename": filename,
                        "drop_levels": drop_levels,
                        "batch_number": batch_num,
                        "filepath": os.path.join(CHECKPOINT_DIR, filename)
                    })
                except ValueError:
                    continue

    return sorted(checkpoint_files, key=lambda x: (x["drop_levels"], x["batch_number"]))


def display_checkpoint_status_and_choose(max_pages, batch_size, num_batches):
    """Hiá»ƒn thá»‹ tráº¡ng thÃ¡i táº¥t cáº£ checkpoint vÃ  cho phÃ©p user chá»n"""
    print("\n" + "="*80)
    print("ğŸ“Š Há»† THá»NG CHECKPOINT THEO DROP_LEVELS + BATCH")
    print("="*80)
    print(
        f"ğŸ“„ Configuration: {max_pages} pages, batch size {batch_size}, {num_batches} batches")

    # Hiá»ƒn thá»‹ cÃ¡c DROP_LEVELS cÃ³ sáºµn
    print("\nğŸ¯ CÃ¡c cáº¥p tÃ²a Ã¡n:")
    for key, name in DROP_LEVELS_OPTIONS.items():
        print(f"  [{key}] {name}")

    # Liá»‡t kÃª táº¥t cáº£ checkpoint hiá»‡n cÃ³
    checkpoints = list_all_checkpoints()
    if checkpoints:
        print(f"\nğŸ“‹ Checkpoint hiá»‡n cÃ³ ({len(checkpoints)} files):")
        for ckpt in checkpoints:
            # Load chi tiáº¿t checkpoint
            data = load_checkpoint(ckpt["drop_levels"], ckpt["batch_number"])
            if data:
                status_icon = "âœ…" if data["is_completed"] else "â³"
                progress = f"{data['last_processed_page']}/{data['end_page']}"
                batch_info = f"Batch {data['batch_number']}"
                if "batch_size" in data:
                    batch_info += f" (size {data['batch_size']})"

                print(f"  {status_icon} {ckpt['filename']}: "
                      f"{batch_info}, Pages {progress}, "
                      f"{data['total_links_found']} links, "
                      f"{data['total_pdfs_downloaded']} PDFs")

                if data["failed_pages"]:
                    print(f"      âŒ Failed pages: {data['failed_pages']}")
    else:
        print("\nğŸ“‹ ChÆ°a cÃ³ checkpoint nÃ o.")

    print("\n" + "-"*50)
    print("ğŸ¯ Chá»n cÃ´ng viá»‡c:")
    print("  1. Táº¡o batch má»›i")
    print("  2. Tiáº¿p tá»¥c batch Ä‘Ã£ cÃ³")

    choice = input("Nháº­p lá»±a chá»n (1/2): ").strip()

    if choice == "1":
        return choose_new_batch(max_pages, batch_size, num_batches)
    elif choice == "2":
        result = choose_existing_batch(checkpoints)
        if result is None:
            print("ğŸ”„ Chuyá»ƒn sang táº¡o batch má»›i...")
            return choose_new_batch(max_pages, batch_size, num_batches)
        return result
    else:
        print("âŒ Lá»±a chá»n khÃ´ng há»£p lá»‡, sá»­ dá»¥ng máº·c Ä‘á»‹nh: táº¡o batch má»›i")
        return choose_new_batch(max_pages, batch_size, num_batches)


def choose_new_batch(max_pages, batch_size, num_batches):
    """Cho phÃ©p user chá»n DROP_LEVELS vÃ  batch Ä‘á»ƒ táº¡o má»›i"""
    print("\nğŸ†• Táº O BATCH Má»šI")
    print("-" * 30)
    # Chá»‰ cho phÃ©p user chá»n DROP_LEVELS
    drop_levels = input(
        f"Chá»n cáº¥p tÃ²a Ã¡n (TW/CW/T/H hoáº·c Enter cho {DEFAULT_DROP_LEVELS}): ").strip().upper()
    if not drop_levels:
        drop_levels = DEFAULT_DROP_LEVELS
    if drop_levels not in DROP_LEVELS_OPTIONS:
        print(f"âŒ Cáº¥p '{drop_levels}' khÃ´ng há»£p lá»‡, sá»­ dá»¥ng máº·c Ä‘á»‹nh '{DEFAULT_DROP_LEVELS}'")
        drop_levels = DEFAULT_DROP_LEVELS
    print(f"\nâœ… Sáº½ táº¡o batch Ä‘a luá»“ng cho cáº¥p tÃ²a Ã¡n: {drop_levels} ({DROP_LEVELS_OPTIONS[drop_levels]})")
    return drop_levels


def choose_existing_batch(checkpoints):
    """Cho phÃ©p user chá»n batch Ä‘Ã£ cÃ³ Ä‘á»ƒ tiáº¿p tá»¥c"""
    if not checkpoints:
        print("âŒ KhÃ´ng cÃ³ checkpoint nÃ o Ä‘á»ƒ tiáº¿p tá»¥c")
        # KhÃ´ng thá»ƒ gá»i choose_new_batch() vÃ¬ thiáº¿u tham sá»‘, return None Ä‘á»ƒ main xá»­ lÃ½
        return None

    print(f"\nğŸ”„ TIáº¾P Tá»¤C BATCH ÄÃƒ CÃ“")
    print("-" * 30)

    incomplete_checkpoints = []
    for i, ckpt in enumerate(checkpoints):
        data = load_checkpoint(ckpt["drop_levels"], ckpt["batch_number"])
        if data and not data["is_completed"]:
            incomplete_checkpoints.append((i, ckpt, data))
            print(
                f"  [{len(incomplete_checkpoints)}] {ckpt['filename']}: Pages {data['last_processed_page']}/{data['end_page']}")

    if not incomplete_checkpoints:
        print("âŒ KhÃ´ng cÃ³ checkpoint nÃ o chÆ°a hoÃ n thÃ nh")
        return None

    try:
        choice_idx = int(
            input("Chá»n checkpoint Ä‘á»ƒ tiáº¿p tá»¥c (sá»‘ thá»© tá»±): ")) - 1
        if 0 <= choice_idx < len(incomplete_checkpoints):
            original_idx, ckpt, data = incomplete_checkpoints[choice_idx]

            return (ckpt["drop_levels"], ckpt["batch_number"],
                    data["start_page"], data["end_page"], data)
        else:
            print("âŒ Lá»±a chá»n khÃ´ng há»£p lá»‡")
            return None
    except ValueError:
        print("âŒ Vui lÃ²ng nháº­p sá»‘")
        return None


def create_payload(hidden_fields, page, drop_levels):
    """Táº¡o payload cho request tÃ¹y theo page sá»‘ vÃ  drop_levels"""
    if page == 1:
        # Láº§n Ä‘áº§u: báº¥m nÃºt "TÃ¬m kiáº¿m"
        return {
            **hidden_fields,
            "ctl00$Content_home_Public$ctl00$txtKeyword": SEARCH_KEYWORD,
            "ctl00$Content_home_Public$ctl00$Drop_Levels": drop_levels,
            "ctl00$Content_home_Public$ctl00$Ra_Drop_Courts": "",
            "ctl00$Content_home_Public$ctl00$Rad_DATE_FROM": "",
            "ctl00$Content_home_Public$ctl00$cmd_search_banner": "TÃ¬m kiáº¿m"
        }
    else:
        return {
            **hidden_fields,
            "ctl00$Content_home_Public$ctl00$txtKeyword": SEARCH_KEYWORD,
            "ctl00$Content_home_Public$ctl00$Drop_Levels": drop_levels,
            "ctl00$Content_home_Public$ctl00$Ra_Drop_Courts": "",
            "ctl00$Content_home_Public$ctl00$Rad_DATE_FROM": "",
            "ctl00$Content_home_Public$ctl00$DropPages": str(page),
            "__EVENTTARGET": "ctl00$Content_home_Public$ctl00$DropPages",
            "__EVENTARGUMENT": ""
        }


def crawl_page(session, page, hidden_fields, drop_levels):
    """Crawl má»™t page vÃ  tráº£ vá» danh sÃ¡ch links + hidden_fields má»›i"""
    payload = create_payload(hidden_fields, page, drop_levels)

    headers = {
        "User-Agent": "Mozilla/5.0",
        "Content-Type": "application/x-www-form-urlencoded"
    }

    try:
        response = session.post(BASE_URL, data=payload,
                                headers=headers, verify=False)
        response.raise_for_status()

        print(
            f"ğŸ“„ Page {page} (DROP_LEVELS={drop_levels}) fetched successfully.")

        soup = BeautifulSoup(response.text, "html.parser")

        links = [a["href"] for a in soup.find_all("a", href=True)]
        page_links = []

        for link in links:
            text_split = link.split("/")
            if len(text_split) > 2 and text_split[2] == "chi-tiet-ban-an":
                full_link = BASE_DOMAIN + link
                page_links.append(full_link)

        new_hidden_fields = get_hidden_fields(response.text)
        print(f"âœ… Found {len(page_links)} detail links on page {page}")
        return page_links, new_hidden_fields, True

    except RequestException as e:
        print(f"âŒ Error on page {page}: {e}")
        return [], hidden_fields, False


def process_and_deduplicate_links(all_links):
    """Xá»­ lÃ½ vÃ  loáº¡i bá» duplicate links"""
    set_all_links = set(all_links)
    list_all_links = list(set_all_links)
    print(f"Total unique links collected: {len(list_all_links)}")
    return list_all_links


def download_all_pdfs(links, session):
    """Download táº¥t cáº£ PDF tá»« danh sÃ¡ch links"""
    if not os.path.exists(DATASET_DIR):
        os.makedirs(DATASET_DIR)

    for i, link in enumerate(links):
        print(f"{i+1}: {link}")
        download_pdf(link, session)


# --- ÄA LUá»’NG: má»—i batch lÃ  1 luá»“ng Ä‘á»™c láº­p ---


def batch_worker(drop_levels, batch_num, start_page, end_page, max_pages, batch_size, existing_checkpoint=None):
    print(
        f"\nğŸš€ [BATCH {batch_num}] Báº¯t Ä‘áº§u tá»« page {start_page} Ä‘áº¿n {end_page} (DROP_LEVELS={drop_levels})")
    session, hidden_fields = initialize_session()
    if existing_checkpoint:
        checkpoint_data = existing_checkpoint
        print(
            f"[BATCH {batch_num}] ğŸ”„ Tiáº¿p tá»¥c tá»« page {checkpoint_data['last_processed_page'] + 1}")
        start_from_page = checkpoint_data['last_processed_page'] + 1
    else:
        checkpoint_data = create_checkpoint_structure(
            drop_levels, batch_num, start_page, end_page, max_pages, batch_size)
        save_checkpoint(checkpoint_data)
        print(
            f"[BATCH {batch_num}] ğŸ†• Táº¡o checkpoint má»›i: {get_checkpoint_filename(drop_levels, batch_num)}")
        start_from_page = start_page

    for page in range(start_from_page, end_page + 1):
        print(f"[BATCH {batch_num}] --- Processing Page {page}/{end_page} ---")
        page_links, hidden_fields, success = crawl_page(
            session, page, hidden_fields, drop_levels)
        checkpoint_data = update_checkpoint_progress(
            checkpoint_data, page, len(page_links), success)
        if success:
            print(
                f"[BATCH {batch_num}] âœ… Page {page} hoÃ n thÃ nh: {len(page_links)} links")
            for i, link in enumerate(page_links):
                print(
                    f"[BATCH {batch_num}]    ğŸ“„ Downloading PDF {i+1}/{len(page_links)}: {link}")
                try:
                    download_pdf(link, session)
                    checkpoint_data["total_pdfs_downloaded"] += 1
                except Exception as e:
                    print(f"[BATCH {batch_num}]    âŒ Lá»—i download: {e}")
        else:
            print(f"[BATCH {batch_num}] âŒ Page {page} tháº¥t báº¡i")
        save_checkpoint(checkpoint_data)
        progress_percent = ((page - start_page + 1) /
                            (end_page - start_page + 1)) * 100
        print(
            f"[BATCH {batch_num}] ğŸ“ˆ Progress: {progress_percent:.1f}% ({page - start_page + 1}/{end_page - start_page + 1} pages)")
        time.sleep(1)
    checkpoint_data["is_completed"] = True
    save_checkpoint(checkpoint_data)
    print(f"[BATCH {batch_num}] ğŸ‰ HOÃ€N THÃ€NH!")


def main():
    print("ğŸš€ CRAWL Dá»® LIá»†U Báº¢N ÃN - ÄA LUá»’NG THEO BATCH")
    max_pages, batch_size, num_batches = get_user_configuration()

    # Gom cÃ¡c batch thÃ nh danh sÃ¡ch
    batch_jobs = []
    for batch_num in range(1, num_batches + 1):
        start_page, end_page = get_batch_page_range(
            batch_num, batch_size, max_pages)
        batch_jobs.append({
            "batch_num": batch_num,
            "start_page": start_page,
            "end_page": end_page
        })

    # Hiá»ƒn thá»‹ tráº¡ng thÃ¡i checkpoint vÃ  cho user chá»n DROP_LEVELS
    drop_levels = display_checkpoint_status_and_choose(
        max_pages, batch_size, num_batches)

    # Chuáº©n bá»‹ checkpoint cho tá»«ng batch (náº¿u cÃ³)
    checkpoints = list_all_checkpoints()
    batch_ckpt_map = {}
    for ckpt in checkpoints:
        if ckpt["drop_levels"] == drop_levels:
            batch_ckpt_map[ckpt["batch_number"]] = load_checkpoint(
                drop_levels, ckpt["batch_number"])

    # Sá»‘ luá»“ng tá»‘i Ä‘a lÃ  10 hoáº·c sá»‘ batch
    max_workers = min(10, num_batches)
    print(f"\nğŸ§µ Sá»­ dá»¥ng tá»‘i Ä‘a {max_workers} luá»“ng song song!")

    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = []
        for job in batch_jobs:
            batch_num = job["batch_num"]
            start_page = job["start_page"]
            end_page = job["end_page"]
            existing_ckpt = batch_ckpt_map.get(batch_num)
            futures.append(executor.submit(
                batch_worker,
                drop_levels,
                batch_num,
                start_page,
                end_page,
                max_pages,
                batch_size,
                existing_ckpt
            ))
        # Äá»£i táº¥t cáº£ batch hoÃ n thÃ nh
        for future in concurrent.futures.as_completed(futures):
            future.result()

    print("\nğŸ‰ Táº¤T Cáº¢ BATCH ÄÃƒ HOÃ€N THÃ€NH!")


if __name__ == "__main__":
    main()
