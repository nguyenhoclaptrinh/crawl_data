import json
import requests
from requests.exceptions import RequestException
from bs4 import BeautifulSoup
import urllib3
import time
import os
from crawl_url_pdf import download_pdf
from config import (BASE_URL, BASE_DOMAIN, DATASET_DIR, CHECKPOINT_DIR, 
                   DEFAULT_MAX_PAGES, DEFAULT_BATCH_SIZE, MIN_BATCH_SIZE, MAX_BATCH_SIZE,
                   DROP_LEVELS_OPTIONS, DEFAULT_DROP_LEVELS, SEARCH_KEYWORD)
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)


def get_hidden_fields(response):
    try:
        soup = BeautifulSoup(response, "html.parser")

        hidden = {}

        for input_tag in soup.find_all("input", type="hidden"):
            if input_tag.get("name") and input_tag.get("value"):
                hidden[input_tag["name"]] = input_tag["value"]

        return hidden
    except RequestException as e:
        print(f"Error fetching hidden fields: {e}")
        return {}


def initialize_session():
    """Kh·ªüi t·∫°o session v√† l·∫•y hidden fields ban ƒë·∫ßu"""
    session = requests.Session()
    response = session.get(BASE_URL, verify=False)
    response.raise_for_status()
    hidden_fields = get_hidden_fields(response.text)
    return session, hidden_fields


def get_user_configuration():
    """Cho ph√©p user nh·∫≠p maxpages v√† t·ª± ƒë·ªông t√≠nh to√°n batch configuration"""
    print("\n" + "="*60)
    print("‚öôÔ∏è  C·∫§U H√åNH CRAWL DATA")
    print("="*60)
    
    # Nh·∫≠p s·ªë pages t·ªëi ƒëa
    while True:
        try:
            max_pages_input = input(f"üìÑ Nh·∫≠p s·ªë pages t·ªëi ƒëa ƒë·ªÉ crawl (m·∫∑c ƒë·ªãnh {DEFAULT_MAX_PAGES}): ").strip()
            if not max_pages_input:
                max_pages = DEFAULT_MAX_PAGES
            else:
                max_pages = int(max_pages_input)
                if max_pages <= 0:
                    print("‚ùå S·ªë pages ph·∫£i l·ªõn h∆°n 0")
                    continue
            break
        except ValueError:
            print("‚ùå Vui l√≤ng nh·∫≠p s·ªë nguy√™n h·ª£p l·ªá")
    
    # T·ª± ƒë·ªông t√≠nh to√°n batch size t·ªëi ∆∞u ho·∫∑c cho user ch·ªçn
    print(f"\nüìä V·ªõi {max_pages} pages, c√°c t√πy ch·ªçn batch size:")
    
    # T√≠nh to√°n c√°c t√πy ch·ªçn batch size h·ª£p l√Ω
    batch_options = calculate_batch_options(max_pages)
    
    for i, option in enumerate(batch_options):
        batch_size = option["batch_size"]
        num_batches = option["num_batches"] 
        efficiency = option["efficiency"]
        print(f"  [{i+1}] Batch size {batch_size}: {num_batches} batches (hi·ªáu qu·∫£: {efficiency:.1f}%)")
    
    print(f"  [0] T·ª± nh·∫≠p batch size")
    
    # User ch·ªçn batch size
    while True:
        try:
            choice = input(f"\nCh·ªçn t√πy ch·ªçn (1-{len(batch_options)} ho·∫∑c 0): ").strip()
            if not choice:
                # M·∫∑c ƒë·ªãnh ch·ªçn t√πy ch·ªçn ƒë·∫ßu ti√™n (t·ªëi ∆∞u nh·∫•t)
                chosen_batch_size = batch_options[0]["batch_size"]
                break
            
            choice_num = int(choice)
            if choice_num == 0:
                chosen_batch_size = get_custom_batch_size(max_pages)
                break
            elif 1 <= choice_num <= len(batch_options):
                chosen_batch_size = batch_options[choice_num - 1]["batch_size"]
                break
            else:
                print(f"‚ùå Vui l√≤ng ch·ªçn t·ª´ 0 ƒë·∫øn {len(batch_options)}")
        except ValueError:
            print("‚ùå Vui l√≤ng nh·∫≠p s·ªë nguy√™n h·ª£p l·ªá")
    
    # T√≠nh to√°n s·ªë batches
    num_batches = calculate_num_batches(max_pages, chosen_batch_size)
    
    print(f"\n‚úÖ C·∫•u h√¨nh ƒë√£ ch·ªçn:")
    print(f"   üìÑ Max pages: {max_pages}")
    print(f"   üì¶ Batch size: {chosen_batch_size}")
    print(f"   üî¢ S·ªë batches: {num_batches}")
    print(f"   üìä Pages trong batch cu·ªëi: {max_pages % chosen_batch_size if max_pages % chosen_batch_size != 0 else chosen_batch_size}")
    
    return max_pages, chosen_batch_size, num_batches


def calculate_batch_options(max_pages):
    """T√≠nh to√°n c√°c t√πy ch·ªçn batch size h·ª£p l√Ω"""
    options = []
    
    # Th·ª≠ c√°c batch size t·ª´ MIN ƒë·∫øn MAX
    for batch_size in range(MIN_BATCH_SIZE, min(MAX_BATCH_SIZE, max_pages) + 1):
        num_batches = calculate_num_batches(max_pages, batch_size)
        
        # T√≠nh hi·ªáu qu·∫£ (% pages ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·∫ßy ƒë·ªß)
        full_batches = max_pages // batch_size
        remaining_pages = max_pages % batch_size
        if remaining_pages == 0:
            efficiency = 100.0
        else:
            efficiency = (full_batches * batch_size + remaining_pages) / (num_batches * batch_size) * 100
        
        options.append({
            "batch_size": batch_size,
            "num_batches": num_batches,
            "efficiency": efficiency
        })
    
    # S·∫Øp x·∫øp theo hi·ªáu qu·∫£ gi·∫£m d·∫ßn, r·ªìi theo batch size tƒÉng d·∫ßn
    options.sort(key=lambda x: (-x["efficiency"], x["batch_size"]))
    
    # Ch·ªâ tr·∫£ v·ªÅ 5 t√πy ch·ªçn t·ªët nh·∫•t
    return options[:5]


def get_custom_batch_size(max_pages):
    """Cho ph√©p user nh·∫≠p batch size t√πy ch·ªânh"""
    while True:
        try:
            batch_size = int(input(f"üì¶ Nh·∫≠p batch size ({MIN_BATCH_SIZE}-{min(MAX_BATCH_SIZE, max_pages)}): "))
            if MIN_BATCH_SIZE <= batch_size <= min(MAX_BATCH_SIZE, max_pages):
                return batch_size
            else:
                print(f"‚ùå Batch size ph·∫£i t·ª´ {MIN_BATCH_SIZE} ƒë·∫øn {min(MAX_BATCH_SIZE, max_pages)}")
        except ValueError:
            print("‚ùå Vui l√≤ng nh·∫≠p s·ªë nguy√™n h·ª£p l·ªá")


def calculate_num_batches(max_pages, batch_size):
    """T√≠nh s·ªë batches c·∫ßn thi·∫øt"""
    return (max_pages + batch_size - 1) // batch_size  # Ceiling division


def get_batch_page_range(batch_num, batch_size, max_pages):
    """T√≠nh to√°n start_page v√† end_page cho m·ªôt batch c·ª• th·ªÉ"""
    start_page = (batch_num - 1) * batch_size + 1
    end_page = min(batch_num * batch_size, max_pages)
    return start_page, end_page


def get_checkpoint_filename(drop_levels, batch_num):
    """T·∫°o t√™n file checkpoint theo DROP_LEVELS v√† batch number"""
    # X·ª≠ l√Ω tr∆∞·ªùng h·ª£p DROP_LEVELS r·ªóng
    level_code = drop_levels if drop_levels else "ALL"
    return f"checkpoint_{level_code}_{batch_num}.json"


def get_checkpoint_filepath(drop_levels, batch_num):
    """L·∫•y ƒë∆∞·ªùng d·∫´n ƒë·∫ßy ƒë·ªß c·ªßa file checkpoint"""
    if not os.path.exists(CHECKPOINT_DIR):
        os.makedirs(CHECKPOINT_DIR)
    
    filename = get_checkpoint_filename(drop_levels, batch_num)
    return os.path.join(CHECKPOINT_DIR, filename)


def create_checkpoint_structure(drop_levels, batch_num, start_page, end_page, max_pages, batch_size):
    """T·∫°o c·∫•u tr√∫c checkpoint m·ªõi v·ªõi th√¥ng tin batch configuration"""
    return {
        "drop_levels": drop_levels,
        "drop_levels_name": DROP_LEVELS_OPTIONS.get(drop_levels, f"C·∫•p {drop_levels}"),
        "batch_number": batch_num,
        "batch_size": batch_size,
        "max_pages": max_pages,
        "start_page": start_page,
        "end_page": end_page,
        "last_processed_page": 0,  # Page cu·ªëi c√πng ƒë√£ x·ª≠ l√Ω th√†nh c√¥ng
        "total_links_found": 0,
        "total_pdfs_downloaded": 0,
        "failed_pages": [],
        "completed_pages": [],
        "created_at": time.time(),
        "last_updated": time.time(),
        "is_completed": False
    }


def load_checkpoint(drop_levels, batch_num):
    """T·∫£i checkpoint t·ª´ file c·ª• th·ªÉ"""
    filepath = get_checkpoint_filepath(drop_levels, batch_num)
    
    if os.path.exists(filepath):
        with open(filepath, "r", encoding="utf-8") as f:
            checkpoint_data = json.load(f)
            print(f"‚úÖ Loaded checkpoint: {get_checkpoint_filename(drop_levels, batch_num)}")
            print(f"   üìÑ Pages: {checkpoint_data['start_page']}-{checkpoint_data['end_page']}")
            print(f"   ‚úèÔ∏è  Last processed: {checkpoint_data['last_processed_page']}")
            print(f"   üîó Links found: {checkpoint_data['total_links_found']}")
            print(f"   üì• PDFs downloaded: {checkpoint_data['total_pdfs_downloaded']}")
            return checkpoint_data
    else:
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y checkpoint: {get_checkpoint_filename(drop_levels, batch_num)}")
        return None


def save_checkpoint(checkpoint_data):
    """L∆∞u checkpoint v√†o file"""
    checkpoint_data["last_updated"] = time.time()
    
    filepath = get_checkpoint_filepath(
        checkpoint_data["drop_levels"], 
        checkpoint_data["batch_number"]
    )
    
    with open(filepath, "w", encoding="utf-8") as f:
        json.dump(checkpoint_data, f, indent=2, ensure_ascii=False)
    
    filename = get_checkpoint_filename(
        checkpoint_data["drop_levels"], 
        checkpoint_data["batch_number"]
    )
    print(f"üíæ Saved checkpoint: {filename}")


def update_checkpoint_progress(checkpoint_data, page_num, links_found, success=True):
    """C·∫≠p nh·∫≠t ti·∫øn ƒë·ªô x·ª≠ l√Ω page"""
    if success:
        if page_num not in checkpoint_data["completed_pages"]:
            checkpoint_data["completed_pages"].append(page_num)
            checkpoint_data["total_links_found"] += links_found
        
        # C·∫≠p nh·∫≠t last_processed_page
        if page_num > checkpoint_data["last_processed_page"]:
            checkpoint_data["last_processed_page"] = page_num
        
        # X√≥a kh·ªèi failed_pages n·∫øu c√≥
        if page_num in checkpoint_data["failed_pages"]:
            checkpoint_data["failed_pages"].remove(page_num)
    else:
        if page_num not in checkpoint_data["failed_pages"]:
            checkpoint_data["failed_pages"].append(page_num)
    
    # Ki·ªÉm tra xem batch ƒë√£ ho√†n th√†nh ch∆∞a
    if checkpoint_data["last_processed_page"] >= checkpoint_data["end_page"]:
        checkpoint_data["is_completed"] = True
    
    return checkpoint_data


def list_all_checkpoints():
    """Li·ªát k√™ t·∫•t c·∫£ checkpoint files c√≥ s·∫µn"""
    if not os.path.exists(CHECKPOINT_DIR):
        return []
    
    checkpoint_files = []
    for filename in os.listdir(CHECKPOINT_DIR):
        if filename.startswith("checkpoint_") and filename.endswith(".json"):
            # Parse filename: checkpoint_{drop_levels}_{batch}.json
            parts = filename.replace("checkpoint_", "").replace(".json", "").split("_")
            if len(parts) >= 2:
                drop_levels = parts[0] if parts[0] != "ALL" else ""
                try:
                    batch_num = int(parts[1])
                    checkpoint_files.append({
                        "filename": filename,
                        "drop_levels": drop_levels,
                        "batch_number": batch_num,
                        "filepath": os.path.join(CHECKPOINT_DIR, filename)
                    })
                except ValueError:
                    continue
    
    return sorted(checkpoint_files, key=lambda x: (x["drop_levels"], x["batch_number"]))


def display_checkpoint_status_and_choose(max_pages, batch_size, num_batches):
    """Hi·ªÉn th·ªã tr·∫°ng th√°i t·∫•t c·∫£ checkpoint v√† cho ph√©p user ch·ªçn"""
    print("\n" + "="*80)
    print("üìä H·ªÜ TH·ªêNG CHECKPOINT THEO DROP_LEVELS + BATCH")
    print("="*80)
    print(f"üìÑ Configuration: {max_pages} pages, batch size {batch_size}, {num_batches} batches")
    
    # Hi·ªÉn th·ªã c√°c DROP_LEVELS c√≥ s·∫µn
    print("\nüéØ C√°c c·∫•p t√≤a √°n:")
    for key, name in DROP_LEVELS_OPTIONS.items():
        print(f"  [{key}] {name}")
    
    # Li·ªát k√™ t·∫•t c·∫£ checkpoint hi·ªán c√≥
    checkpoints = list_all_checkpoints()
    if checkpoints:
        print(f"\nüìã Checkpoint hi·ªán c√≥ ({len(checkpoints)} files):")
        for ckpt in checkpoints:
            # Load chi ti·∫øt checkpoint
            data = load_checkpoint(ckpt["drop_levels"], ckpt["batch_number"])
            if data:
                status_icon = "‚úÖ" if data["is_completed"] else "‚è≥"
                progress = f"{data['last_processed_page']}/{data['end_page']}"
                batch_info = f"Batch {data['batch_number']}"
                if "batch_size" in data:
                    batch_info += f" (size {data['batch_size']})"
                
                print(f"  {status_icon} {ckpt['filename']}: "
                      f"{batch_info}, Pages {progress}, "
                      f"{data['total_links_found']} links, "
                      f"{data['total_pdfs_downloaded']} PDFs")
                
                if data["failed_pages"]:
                    print(f"      ‚ùå Failed pages: {data['failed_pages']}")
    else:
        print("\nüìã Ch∆∞a c√≥ checkpoint n√†o.")
    
    print("\n" + "-"*50)
    print("üéØ Ch·ªçn c√¥ng vi·ªác:")
    print("  1. T·∫°o batch m·ªõi")
    print("  2. Ti·∫øp t·ª•c batch ƒë√£ c√≥")
    
    choice = input("Nh·∫≠p l·ª±a ch·ªçn (1/2): ").strip()
    
    if choice == "1":
        return choose_new_batch(max_pages, batch_size, num_batches)
    elif choice == "2":
        result = choose_existing_batch(checkpoints)
        if result is None:
            print("üîÑ Chuy·ªÉn sang t·∫°o batch m·ªõi...")
            return choose_new_batch(max_pages, batch_size, num_batches)
        return result
    else:
        print("‚ùå L·ª±a ch·ªçn kh√¥ng h·ª£p l·ªá, s·ª≠ d·ª•ng m·∫∑c ƒë·ªãnh: t·∫°o batch m·ªõi")
        return choose_new_batch(max_pages, batch_size, num_batches)


def choose_new_batch(max_pages, batch_size, num_batches):
    """Cho ph√©p user ch·ªçn DROP_LEVELS v√† batch ƒë·ªÉ t·∫°o m·ªõi"""
    print("\nüÜï T·∫†O BATCH M·ªöI")
    print("-" * 30)
    
    # Ch·ªçn DROP_LEVELS
    drop_levels = input(f"Ch·ªçn c·∫•p t√≤a √°n (TW/CW/T/H ho·∫∑c Enter cho {DEFAULT_DROP_LEVELS}): ").strip().upper()
    if not drop_levels:
        drop_levels = DEFAULT_DROP_LEVELS
    
    if drop_levels not in DROP_LEVELS_OPTIONS:
        print(f"‚ùå C·∫•p '{drop_levels}' kh√¥ng h·ª£p l·ªá, s·ª≠ d·ª•ng m·∫∑c ƒë·ªãnh '{DEFAULT_DROP_LEVELS}'")
        drop_levels = DEFAULT_DROP_LEVELS
    
    # Hi·ªÉn th·ªã c√°c batch c√≥ s·∫µn
    print(f"\nüì¶ C√°c batch c√≥ s·∫µn (total {num_batches} batches):")
    for i in range(1, num_batches + 1):
        start_page, end_page = get_batch_page_range(i, batch_size, max_pages)
        print(f"  Batch {i}: Pages {start_page}-{end_page} ({end_page - start_page + 1} pages)")
    
    # Ch·ªçn batch
    while True:
        try:
            batch_num = int(input(f"Ch·ªçn s·ªë batch (1-{num_batches}): "))
            if 1 <= batch_num <= num_batches:
                break
            else:
                print(f"‚ùå Batch ph·∫£i t·ª´ 1 ƒë·∫øn {num_batches}")
        except ValueError:
            print("‚ùå Vui l√≤ng nh·∫≠p s·ªë nguy√™n h·ª£p l·ªá")
    
    # T√≠nh to√°n start_page v√† end_page
    start_page, end_page = get_batch_page_range(batch_num, batch_size, max_pages)
    
    print(f"\n‚úÖ S·∫Ω t·∫°o batch m·ªõi:")
    print(f"   üìÇ DROP_LEVELS: {drop_levels} ({DROP_LEVELS_OPTIONS[drop_levels]})")
    print(f"   üì¶ Batch: {batch_num}/{num_batches}")
    print(f"   üìÑ Pages: {start_page} - {end_page} ({end_page - start_page + 1} pages)")
    
    return drop_levels, batch_num, start_page, end_page, None


def choose_existing_batch(checkpoints):
    """Cho ph√©p user ch·ªçn batch ƒë√£ c√≥ ƒë·ªÉ ti·∫øp t·ª•c"""
    if not checkpoints:
        print("‚ùå Kh√¥ng c√≥ checkpoint n√†o ƒë·ªÉ ti·∫øp t·ª•c")
        # Kh√¥ng th·ªÉ g·ªçi choose_new_batch() v√¨ thi·∫øu tham s·ªë, return None ƒë·ªÉ main x·ª≠ l√Ω
        return None
    
    print(f"\nüîÑ TI·∫æP T·ª§C BATCH ƒê√É C√ì")
    print("-" * 30)
    
    incomplete_checkpoints = []
    for i, ckpt in enumerate(checkpoints):
        data = load_checkpoint(ckpt["drop_levels"], ckpt["batch_number"])
        if data and not data["is_completed"]:
            incomplete_checkpoints.append((i, ckpt, data))
            print(f"  [{len(incomplete_checkpoints)}] {ckpt['filename']}: Pages {data['last_processed_page']}/{data['end_page']}")
    
    if not incomplete_checkpoints:
        print("‚ùå Kh√¥ng c√≥ checkpoint n√†o ch∆∞a ho√†n th√†nh")
        return None
    
    try:
        choice_idx = int(input("Ch·ªçn checkpoint ƒë·ªÉ ti·∫øp t·ª•c (s·ªë th·ª© t·ª±): ")) - 1
        if 0 <= choice_idx < len(incomplete_checkpoints):
            original_idx, ckpt, data = incomplete_checkpoints[choice_idx]
            
            return (ckpt["drop_levels"], ckpt["batch_number"], 
                   data["start_page"], data["end_page"], data)
        else:
            print("‚ùå L·ª±a ch·ªçn kh√¥ng h·ª£p l·ªá")
            return None
    except ValueError:
        print("‚ùå Vui l√≤ng nh·∫≠p s·ªë")
        return None


def create_payload(hidden_fields, page, drop_levels):
    """T·∫°o payload cho request t√πy theo page s·ªë v√† drop_levels"""
    if page == 1:
        # L·∫ßn ƒë·∫ßu: b·∫•m n√∫t "T√¨m ki·∫øm"
        return {
            **hidden_fields,
            "ctl00$Content_home_Public$ctl00$txtKeyword": SEARCH_KEYWORD,
            "ctl00$Content_home_Public$ctl00$Drop_Levels": drop_levels,
            "ctl00$Content_home_Public$ctl00$Ra_Drop_Courts": "",
            "ctl00$Content_home_Public$ctl00$Rad_DATE_FROM": "",
            "ctl00$Content_home_Public$ctl00$cmd_search_banner": "T√¨m ki·∫øm"
        }
    else:
        return {
            **hidden_fields,
            "ctl00$Content_home_Public$ctl00$txtKeyword": SEARCH_KEYWORD,
            "ctl00$Content_home_Public$ctl00$Drop_Levels": drop_levels,
            "ctl00$Content_home_Public$ctl00$Ra_Drop_Courts": "",
            "ctl00$Content_home_Public$ctl00$Rad_DATE_FROM": "",
            "ctl00$Content_home_Public$ctl00$DropPages": str(page),
            "__EVENTTARGET": "ctl00$Content_home_Public$ctl00$DropPages",
            "__EVENTARGUMENT": ""
        }


def crawl_page(session, page, hidden_fields, drop_levels):
    """Crawl m·ªôt page v√† tr·∫£ v·ªÅ danh s√°ch links + hidden_fields m·ªõi"""
    payload = create_payload(hidden_fields, page, drop_levels)
    
    headers = {
        "User-Agent": "Mozilla/5.0",
        "Content-Type": "application/x-www-form-urlencoded"
    }

    try:
        response = session.post(BASE_URL, data=payload, headers=headers, verify=False)
        response.raise_for_status()
        
        print(f"üìÑ Page {page} (DROP_LEVELS={drop_levels}) fetched successfully.")
        
        soup = BeautifulSoup(response.text, "html.parser")
        
        links = [a["href"] for a in soup.find_all("a", href=True)]
        page_links = []
        
        for link in links:
            text_split = link.split("/")
            if len(text_split) > 2 and text_split[2] == "chi-tiet-ban-an":
                full_link = BASE_DOMAIN + link
                page_links.append(full_link)
        
        new_hidden_fields = get_hidden_fields(response.text)
        print(f"‚úÖ Found {len(page_links)} detail links on page {page}")
        return page_links, new_hidden_fields, True
        
    except RequestException as e:
        print(f"‚ùå Error on page {page}: {e}")
        return [], hidden_fields, False


def process_and_deduplicate_links(all_links):
    """X·ª≠ l√Ω v√† lo·∫°i b·ªè duplicate links"""
    set_all_links = set(all_links)
    list_all_links = list(set_all_links)
    print(f"Total unique links collected: {len(list_all_links)}")
    return list_all_links


def download_all_pdfs(links, session):
    """Download t·∫•t c·∫£ PDF t·ª´ danh s√°ch links"""
    if not os.path.exists(DATASET_DIR):
        os.makedirs(DATASET_DIR)

    for i, link in enumerate(links):
        print(f"{i+1}: {link}")
        download_pdf(link, session)


def main():
    """H√†m ch√≠nh ƒëi·ªÅu ph·ªëi to√†n b·ªô qu√° tr√¨nh crawl v·ªõi batch configuration t·ª± ƒë·ªông"""
    print("üöÄ CRAWL D·ªÆ LI·ªÜU B·∫¢N √ÅN - H·ªÜ TH·ªêNG BATCH T·ª∞ ƒê·ªòNG")
    
    # B∆∞·ªõc 1: User c·∫•u h√¨nh maxpages v√† batch size
    max_pages, batch_size, num_batches = get_user_configuration()
    
    # B∆∞·ªõc 2: Kh·ªüi t·∫°o session v√† hidden fields
    session, hidden_fields = initialize_session()
    
    # B∆∞·ªõc 3: Hi·ªÉn th·ªã tr·∫°ng th√°i checkpoint v√† cho user ch·ªçn
    drop_levels, batch_num, start_page, end_page, existing_checkpoint = display_checkpoint_status_and_choose(
        max_pages, batch_size, num_batches)
    
    # B∆∞·ªõc 4: T·∫°o ho·∫∑c load checkpoint
    if existing_checkpoint:
        checkpoint_data = existing_checkpoint
        print(f"\nüîÑ Ti·∫øp t·ª•c t·ª´ page {checkpoint_data['last_processed_page'] + 1}")
        start_from_page = checkpoint_data['last_processed_page'] + 1
    else:
        checkpoint_data = create_checkpoint_structure(
            drop_levels, batch_num, start_page, end_page, max_pages, batch_size)
        save_checkpoint(checkpoint_data)
        print(f"\nüÜï T·∫°o checkpoint m·ªõi: {get_checkpoint_filename(drop_levels, batch_num)}")
        start_from_page = start_page
    
    # B∆∞·ªõc 5: Crawl c√°c pages
    all_links = []
    print(f"\nüìÑ B·∫Øt ƒë·∫ßu crawl pages {start_from_page} ƒë·∫øn {end_page}...")
    print(f"üìä Batch {batch_num}/{num_batches} - DROP_LEVELS: {drop_levels}")
    
    for page in range(start_from_page, end_page + 1):
        print(f"\n--- Processing Page {page}/{end_page} ---")
        
        page_links, hidden_fields, success = crawl_page(session, page, hidden_fields, drop_levels)
        
        # C·∫≠p nh·∫≠t checkpoint progress
        checkpoint_data = update_checkpoint_progress(checkpoint_data, page, len(page_links), success)
        
        if success:
            all_links.extend(page_links)
            print(f"‚úÖ Page {page} ho√†n th√†nh: {len(page_links)} links")
        else:
            print(f"‚ùå Page {page} th·∫•t b·∫°i")
        
        # L∆∞u checkpoint sau m·ªói page
        save_checkpoint(checkpoint_data)
        
        # Hi·ªÉn th·ªã progress
        progress_percent = ((page - start_page + 1) / (end_page - start_page + 1)) * 100
        print(f"üìà Progress: {progress_percent:.1f}% ({page - start_page + 1}/{end_page - start_page + 1} pages)")
        
        # Ngh·ªâ ng·∫Øn ƒë·ªÉ tr√°nh spam server
        time.sleep(1)
    
    # B∆∞·ªõc 6: X·ª≠ l√Ω v√† lo·∫°i b·ªè duplicate links
    unique_links = process_and_deduplicate_links(all_links)
    
    # B∆∞·ªõc 7: Download t·∫•t c·∫£ PDF
    print(f"\nüì• B·∫Øt ƒë·∫ßu download {len(unique_links)} PDFs...")
    pdf_count = 0
    for i, link in enumerate(unique_links):
        print(f"üìÑ {i+1}/{len(unique_links)}: {link}")
        try:
            download_pdf(link, session)
            pdf_count += 1
        except Exception as e:
            print(f"‚ùå L·ªói download: {e}")
        
        # C·∫≠p nh·∫≠t progress download
        if (i + 1) % 10 == 0 or i == len(unique_links) - 1:
            download_progress = ((i + 1) / len(unique_links)) * 100
            print(f"üì• Download progress: {download_progress:.1f}% ({i + 1}/{len(unique_links)} PDFs)")
    
    # B∆∞·ªõc 8: Ho√†n th√†nh v√† b√°o c√°o
    checkpoint_data["total_pdfs_downloaded"] = pdf_count
    checkpoint_data["is_completed"] = True
    save_checkpoint(checkpoint_data)
    
    print(f"\nüéâ HO√ÄN TH√ÄNH BATCH {batch_num}/{num_batches}!")
    print(f"   üìÇ DROP_LEVELS: {drop_levels} ({DROP_LEVELS_OPTIONS[drop_levels]})")
    print(f"   üì¶ Batch size: {batch_size}")
    print(f"   üìÑ Pages: {start_page}-{end_page} ({end_page - start_page + 1} pages)")
    print(f"   üîó Total links: {checkpoint_data['total_links_found']}")
    print(f"   üì• PDFs downloaded: {pdf_count}")
    print(f"   üíæ Checkpoint: {get_checkpoint_filename(drop_levels, batch_num)}")
    
    if batch_num < num_batches:
        print(f"\nüí° C√≤n {num_batches - batch_num} batches ch∆∞a ho√†n th√†nh!")
        print(f"   Ch·∫°y l·∫°i ch∆∞∆°ng tr√¨nh ƒë·ªÉ ti·∫øp t·ª•c batch ti·∫øp theo.")


if __name__ == "__main__":
    main()
